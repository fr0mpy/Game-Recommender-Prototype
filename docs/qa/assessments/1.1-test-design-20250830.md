# Test Design: Story 1.1 - Slot Forge Dual-Engine Production System

Date: 2025-08-30
Designer: Quinn (Test Architect)

## Test Strategy Overview

Based on **actual implemented system** (README analysis):
- **Total test scenarios**: 47
- **Unit tests**: 18 (38%) - Core logic validation
- **Integration tests**: 21 (45%) - Component interaction
- **E2E tests**: 8 (17%) - Critical user journeys
- **Priority distribution**: P0: 15, P1: 18, P2: 10, P3: 4

## System Architecture Context

**Actual Production System** vs Original Story:
- ✅ **Implemented**: Dual similarity engines (Algorithmic + LLM)
- ✅ **Implemented**: Dual explanation system (Smart Templates + LLM)
- ✅ **Implemented**: 14-factor dynamic weight integration
- ✅ **Implemented**: Player context intelligence
- ✅ **Implemented**: Production Vercel deployment with Redis
- ✅ **Beyond Scope**: Enterprise architecture documentation

## Test Scenarios by Component

### 1. LLM Response Quality & Contract Testing (Critical)

#### **P0: LLM Explanation Generation**
| Test ID | Level | Scenario | LLM Testing Strategy | Justification |
|---------|-------|----------|---------------------|---------------|
| 1.1-LLM-001 | Unit | Contract validation - response structure | Structure + field validation | Must validate JSON structure |
| 1.1-LLM-002 | Unit | Dominant factor mention validation | Semantic keyword detection | 100% weight must be mentioned |
| 1.1-LLM-003 | Unit | Weight integration - all 14 factors | Dynamic prompt injection test | Core weight preservation |
| 1.1-LLM-004 | Integration | Golden dataset comparison | Semantic similarity (85% threshold) | Regression protection |
| 1.1-LLM-005 | Integration | Fallback to smart templates | Mock LLM failure scenarios | Critical fallback testing |

#### **P0: BMad Master Similarity Engine**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-SIM-001 | Integration | Semantic theme understanding | Golden pairs testing | Validates Dragons≈Fantasy logic |
| 1.1-SIM-002 | Integration | Context-aware scoring | Time/attention context injection | Context must affect scores |
| 1.1-SIM-003 | Integration | Dynamic weight injection | All 14 weights in prompt validation | Core requirement |
| 1.1-SIM-004 | Unit | Performance boundaries | 15s timeout validation | Production SLA requirement |

### 2. Weight Parsing & Preservation (Critical - Fixed Bug)

#### **P0: Weight Parsing Logic**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-WT-001 | Unit | 0% weight preservation | `theme=0` stays 0, not overridden | Critical bug fix validation |
| 1.1-WT-002 | Unit | 100% weight preservation | `bonusFreq=1` maintains full weight | User preference accuracy |
| 1.1-WT-003 | Unit | Undefined weight handling | Missing form fields get defaults | Form submission edge cases |
| 1.1-WT-004 | Unit | Edge case boundaries | Negative, NaN, >1 values | Input sanitization |
| 1.1-WT-005 | Integration | Form-to-server parsing | POST data serialization | Full request cycle |
| 1.1-WT-006 | Integration | Redis persistence | Settings survive server restart | Serverless compatibility |

### 3. Dual Engine Architecture (High Priority)

#### **P0: Engine Selection & Routing**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-ENG-001 | Integration | Algorithmic engine selection | Toggle UI + performance validation | Fast mode critical |
| 1.1-ENG-002 | Integration | LLM engine selection | Toggle UI + quality validation | Premium mode critical |
| 1.1-ENG-003 | Integration | Engine output standardization | Both return identical structure | API consistency |

#### **P1: Dual Explanation System**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-EXPL-001 | Integration | LLM→LLM explanation routing | Engine detection logic | Revolutionary feature |
| 1.1-EXPL-002 | Integration | Algo→Smart template routing | Cost optimization validation | $0 explanation mode |
| 1.1-EXPL-003 | Unit | Smart template generation | Dominant factor prioritization | Template logic validation |
| 1.1-EXPL-004 | Integration | Explanation fallback chain | LLM fail → Smart template | Graceful degradation |

### 4. Context Intelligence System (High Priority)

#### **P1: Player Context Analysis**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-CTX-001 | Unit | Time context detection | Mock system time scenarios | Work/leisure differentiation |
| 1.1-CTX-002 | Unit | Financial cycle analysis | Day-of-month calculation | Payday proximity logic |
| 1.1-CTX-003 | Unit | Attention span mapping | Device + time → focus level | Context-aware recommendations |
| 1.1-CTX-004 | Integration | Context injection to LLM | Prompt includes context data | LLM receives full context |

### 5. Game Generation & Data Validation

#### **P1: LLM Game Generation**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-GEN-001 | Integration | Single game generation | Schema validation (20+ fields) | Data integrity |
| 1.1-GEN-002 | Integration | Batch generation (100 games) | Parallel chunk processing | Production scenario |
| 1.1-GEN-003 | Unit | Input validation guardrails | Block "sing a song" type requests | Token waste prevention |
| 1.1-GEN-004 | Integration | Redis persistence | Generated games survive restart | Serverless storage |

#### **P2: Data Export Functions**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-EXP-001 | Integration | JSON export integrity | Data structure validation | Export accuracy |
| 1.1-EXP-002 | Integration | CSV export formatting | Parse and validate CSV output | User data download |

### 6. Performance & Cost Management

#### **P0: Performance Boundaries**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-PERF-001 | Integration | Algorithmic speed (<250ms) | Response time measurement | Production SLA |
| 1.1-PERF-002 | Integration | LLM timeout handling (15s) | Long request timeout | User experience |
| 1.1-PERF-003 | E2E | Concurrent user load | Multi-session Redis testing | Scalability validation |

#### **P1: Cost Monitoring**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-COST-001 | Integration | Token usage tracking | Count tokens per operation | Cost management |
| 1.1-COST-002 | Integration | Session cost calculation | $1.31-$1.56 range validation | Budget compliance |

### 7. User Interface & Experience

#### **P1: UI Component Testing**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-UI-001 | E2E | Weight slider functionality | Real-time weight adjustment | Core user interaction |
| 1.1-UI-002 | E2E | Engine toggle operation | Switch between algo/LLM | Feature demonstration |
| 1.1-UI-003 | E2E | Dominant factor display | 80%+ weight badge prominence | User feedback clarity |
| 1.1-UI-004 | Integration | Mobile responsiveness | Cross-device game card rendering | Mobile user experience |

#### **P2: Error Handling & Recovery**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-ERR-001 | Integration | API key missing/invalid | Graceful error messages | User-friendly failures |
| 1.1-ERR-002 | Integration | Redis connection failure | Fallback to local storage | Serverless resilience |
| 1.1-ERR-003 | Unit | Malformed LLM responses | JSON parsing error handling | Robustness |

### 8. Security & Data Protection

#### **P1: API Security**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-SEC-001 | Unit | Environment variable security | No key exposure in logs/errors | API key protection |
| 1.1-SEC-002 | Integration | Input sanitization | Prevent prompt injection | Security guardrails |

### 9. Production Integration & Deployment

#### **P2: Production Environment**
| Test ID | Level | Scenario | Testing Strategy | Justification |
|---------|-------|----------|------------------|---------------|
| 1.1-PROD-001 | E2E | Vercel deployment health | Live system validation | Production readiness |
| 1.1-PROD-002 | Integration | Redis Upstash integration | Cloud storage connectivity | Production data layer |

## LLM Testing Implementation Strategies

### 1. **Contract-Based Testing** (Most Reliable)
```javascript
describe('LLM Explanation Generation', () => {
  test('returns valid explanation structure', async () => {
    const explanations = await generateLLMExplanations(game, recs, weights, context);
    
    expect(explanations).toBeArray();
    expect(explanations).toHaveLength(5);
    
    explanations.forEach(explanation => {
      expect(explanation).toContain('bonus frequency'); // Dominant factor
      expect(explanation).toMatch(/\d+\.?\d*%/);       // Contains percentage
      expect(explanation.length).toBeGreaterThan(30);   // Sufficient detail
      expect(explanation).not.toContain('undefined');   // No template errors
    });
  });
});
```

### 2. **Golden Dataset Validation**
```javascript
describe('LLM Quality Regression', () => {
  const goldenCases = [
    {
      name: 'bonus-frequency-dominant',
      weights: { bonusFrequency: 1.0, theme: 0.0 },
      expectedKeywords: ['bonus frequency', '100%', 'identical'],
      minSimilarity: 0.85
    }
  ];

  goldenCases.forEach(testCase => {
    test(`maintains quality: ${testCase.name}`, async () => {
      const explanation = await generateLLMExplanations(/*...*/);
      
      const hasRequiredKeywords = testCase.expectedKeywords.every(
        keyword => explanation[0].toLowerCase().includes(keyword.toLowerCase())
      );
      expect(hasRequiredKeywords).toBe(true);
      
      // Semantic similarity with known good response
      const similarity = await calculateSemanticSimilarity(
        explanation[0], 
        testCase.expectedResponse
      );
      expect(similarity).toBeGreaterThan(testCase.minSimilarity);
    });
  });
});
```

### 3. **Semantic Validation** (AI-Assisted)
```javascript
describe('LLM Semantic Accuracy', () => {
  test('explanation matches weight priorities', async () => {
    const weights = { bonusFrequency: 1.0, theme: 0.0 };
    const explanation = await generateLLMExplanations(/*...*/);
    
    // Use cheaper LLM to validate main LLM output
    const validation = await validateExplanationAccuracy(explanation[0], weights);
    
    expect(validation.mentionsBonusFrequency).toBe(true);
    expect(validation.emphasizesCorrectFactor).toBe(true);
    expect(validation.accuracyScore).toBeGreaterThan(0.8);
  });
});
```

### 4. **Fallback System Testing**
```javascript
describe('LLM Fallback Reliability', () => {
  test('falls back to smart templates on LLM failure', async () => {
    // Mock LLM to fail
    jest.spyOn(anthropic.messages, 'create')
        .mockRejectedValue(new Error('API Error'));
    
    const result = await getRecommendationsWithExplanations(/*...*/);
    
    // Should fall back to smart templates
    expect(result.explanations[0]).toContain('Perfect bonus frequency match');
    expect(result.source).toBe('smart-template-fallback');
    expect(result.error).toBeUndefined(); // User sees no error
  });
});
```

## Risk Coverage Matrix

### Critical Risks Mitigated
- **LLM-001**: Golden dataset + contract validation
- **WEIGHT-001**: Comprehensive edge case testing  
- **FALLBACK-001**: Failure simulation + graceful degradation

### High Risks Mitigated  
- **PERF-001**: Performance boundary testing
- **COST-001**: Token usage monitoring
- **DATA-001**: Schema validation + sanitization
- **SEC-001**: Environment variable security

## Recommended Execution Order

### Phase 1: Critical Path (Must Pass - 2-3 hours)
1. **Weight parsing tests** (1.1-WT-001 through 1.1-WT-004)
2. **LLM contract validation** (1.1-LLM-001, 1.1-LLM-002)  
3. **Fallback system tests** (1.1-LLM-005, 1.1-EXPL-004)
4. **Performance boundaries** (1.1-PERF-001, 1.1-PERF-002)

### Phase 2: Core Features (Should Pass - 4-6 hours)
1. **Dual engine testing** (1.1-ENG-001 through 1.1-ENG-003)
2. **Explanation system** (1.1-EXPL-001 through 1.1-EXPL-003)
3. **Context intelligence** (1.1-CTX-001 through 1.1-CTX-004)
4. **Game generation** (1.1-GEN-001 through 1.1-GEN-004)

### Phase 3: Polish & Production (Nice to Have - 2-4 hours)
1. **UI/UX validation** (1.1-UI-001 through 1.1-UI-004) 
2. **Error handling** (1.1-ERR-001 through 1.1-ERR-003)
3. **Production integration** (1.1-PROD-001, 1.1-PROD-002)

## Quality Gates Integration

### Test Coverage Gates
- **PASS**: All P0 tests passing, 90% P1 tests passing
- **CONCERNS**: Any P0 failures, <80% P1 pass rate
- **FAIL**: Critical LLM or weight parsing failures

### Performance Gates
- **PASS**: Algorithmic <250ms, LLM <15s, no memory leaks
- **CONCERNS**: Performance within 2x targets
- **FAIL**: Performance >3x targets or system instability

## Test Implementation Priority

### Immediate (This Sprint)
1. **Weight parsing regression tests** - Critical bug fix protection
2. **LLM contract validation** - Production reliability
3. **Fallback system tests** - User experience protection

### Next Sprint  
1. **Golden dataset creation** - LLM quality baseline
2. **Performance boundary testing** - Production SLA validation
3. **Context intelligence validation** - Feature verification

### Future Enhancement
1. **Load testing framework** - Scalability preparation
2. **A/B testing infrastructure** - Engine comparison
3. **Monitoring integration** - Production observability

---

This test design reflects the **actual production system** with dual engines, context intelligence, and enterprise architecture - far beyond the original POC story requirements.